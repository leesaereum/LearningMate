{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>발라드</td>\n",
       "      <td>34431086</td>\n",
       "      <td>839736</td>\n",
       "      <td>취중고백</td>\n",
       "      <td>김민석 (멜로망스)</td>\n",
       "      <td>뭐하고 있었니 늦었지만 잠시 나올래 너의 집 골목에 있는 놀이터에 앉아 있어 친구들...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>발라드</td>\n",
       "      <td>34481682</td>\n",
       "      <td>261143</td>\n",
       "      <td>겨울잠</td>\n",
       "      <td>아이유</td>\n",
       "      <td>때 이른 봄 몇 송이 꺾어다 너의 방 문 앞에 두었어 긴 잠 실컷 자고 나오면 그때...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>발라드</td>\n",
       "      <td>34061322</td>\n",
       "      <td>994944</td>\n",
       "      <td>사랑은 늘 도망가</td>\n",
       "      <td>임영웅</td>\n",
       "      <td>눈물이 난다 이 길을 걸으면 그 사람 손길이 자꾸 생각이 난다 붙잡지 못하고 가슴만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>발라드</td>\n",
       "      <td>34360855</td>\n",
       "      <td>2138620</td>\n",
       "      <td>눈이 오잖아(Feat.헤이즈)</td>\n",
       "      <td>이무진</td>\n",
       "      <td>한 달 좀 덜 된 기억들 주머니에 넣은 채 걷고 있어 몇 시간을 혹시 몰라 네가 좋...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>발라드</td>\n",
       "      <td>33496587</td>\n",
       "      <td>2863470</td>\n",
       "      <td>다정히 내 이름을 부르면</td>\n",
       "      <td>경서예지</td>\n",
       "      <td>끝없이 별빛이 내리던 밤 기분 좋은 바람이 두 빰을 스치고 새벽 바다 한곳을 보는 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  genre   song_id  artist_id         song_name artist_name  \\\n",
       "0   발라드  34431086     839736              취중고백  김민석 (멜로망스)   \n",
       "1   발라드  34481682     261143               겨울잠         아이유   \n",
       "2   발라드  34061322     994944         사랑은 늘 도망가         임영웅   \n",
       "3   발라드  34360855    2138620  눈이 오잖아(Feat.헤이즈)         이무진   \n",
       "4   발라드  33496587    2863470     다정히 내 이름을 부르면        경서예지   \n",
       "\n",
       "                                               lyric  \n",
       "0  뭐하고 있었니 늦었지만 잠시 나올래 너의 집 골목에 있는 놀이터에 앉아 있어 친구들...  \n",
       "1  때 이른 봄 몇 송이 꺾어다 너의 방 문 앞에 두었어 긴 잠 실컷 자고 나오면 그때...  \n",
       "2  눈물이 난다 이 길을 걸으면 그 사람 손길이 자꾸 생각이 난다 붙잡지 못하고 가슴만...  \n",
       "3  한 달 좀 덜 된 기억들 주머니에 넣은 채 걷고 있어 몇 시간을 혹시 몰라 네가 좋...  \n",
       "4  끝없이 별빛이 내리던 밤 기분 좋은 바람이 두 빰을 스치고 새벽 바다 한곳을 보는 ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = pd.read_csv('songs_preprocessed.csv')\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로 데이터셋 객체를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = songs['genre']\n",
    "data = songs['lyric']\n",
    "ds_raw = data.values\n",
    "ds_target = target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토크나이즈 하고 고유 토큰 갯수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "  return okt.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'뭐하고 있었니 늦었지만 잠시 나올래 너의 집 골목에 있는 놀이터에 앉아 있어 친구들 만나서 오랜만에 술을 좀 했는데 자꾸만 니 얼굴 떠올라 무작정 달려왔어 이 맘 모르겠니 요즘 난 미친 사람처럼 너만 생각해 대책없이 네가 점점 좋아져 아냐 안 취했어 진짜야 널 정말 사랑해 눈물이 날만큼 원하고 있어 정말로 몰랐니 가끔 전화해 장난치듯 주말엔 뭐할거냐며 너의 관심 끌던 나를 그리고 한번씩 누나 주려 샀는데 너 그냥 준다고 생색 낸 선물도 너 때문에 산거야 이 맘 모르겠니 요즘 난 미친 사람처럼 너만 생각해 대책없이 네가 점점 좋아져 아냐 안 취했어 진짜야 널 정말 사랑해 진심이야 믿어줘 갑자기 이런 말 놀랐다면 미안해 부담이 되는게 당연해 이해해 널 하지만 내 고백도 이해해 주겠니 oh 지금 당장 대답하진마 나와 일주일만 사귀어줄래 후회없이 잘 해주고 싶은데 그 후에도 니가 싫다면 나 그때 포기할게 귀찮게 안할게 혼자 아플게 진심이야 너를 사랑하고 있어 '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenize(d) for d in ds_raw]\n",
    "\n",
    "for i in range(len(ds_raw)):\n",
    "  ds_raw[i] = tokenize(ds_raw[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('이', 11246),\n",
       " ('을', 7445),\n",
       " ('에', 7261),\n",
       " ('내', 7107),\n",
       " ('가', 6543),\n",
       " ('너', 6343),\n",
       " ('i', 5494),\n",
       " ('나', 5175),\n",
       " ('의', 5056),\n",
       " ('you', 3927)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts = Counter([tk for d in ds_raw for tk in d]) # 중복제거 토큰들\n",
    "token_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 고유 토큰을 정수로 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = {tk: i for i, tk in enumerate(token_counts.keys())}\n",
    "len(encoder)\n",
    "# encoder 확인\n",
    "encoder['you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터를 정수로 변환하고 train, test, valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train test split\n",
    "ds_train, ds_test, target_train, target_test = train_test_split(ds_raw, ds_target, test_size=0.2, random_state=42)\n",
    "# validation split\n",
    "ds_train, ds_val, target_train, target_val = train_test_split(ds_train, target_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "ds_train = [np.array([encoder[tk] for tk in d]) for d in ds_train]\n",
    "ds_val = [np.array([encoder[tk] for tk in d]) for d in ds_val]\n",
    "ds_test = [np.array([encoder[tk] for tk in d]) for d in ds_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "phrase input should be string, not <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/51/xmc_l6t13wv1nc5z6qmyg58r0000gn/T/ipykernel_19350/3635972097.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mds_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mds_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/51/xmc_l6t13wv1nc5z6qmyg58r0000gn/T/ipykernel_19350/1965319949.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mokt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/konlpy/tag/_okt.py\u001b[0m in \u001b[0;36mmorphs\u001b[0;34m(self, phrase, norm, stem)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;34m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mphrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/konlpy/tag/_okt.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mjoined\u001b[0m \u001b[0msets\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmorph\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \"\"\"\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mvalidate_phrase_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         tokens = self.jki.tokenize(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/konlpy/tag/_common.py\u001b[0m in \u001b[0;36mvalidate_phrase_inputs\u001b[0;34m(phrase)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m     19\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"phrase input should be string, not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: phrase input should be string, not <class 'list'>"
     ]
    }
   ],
   "source": [
    "for i in range(len(ds_train)):\n",
    "  ds_train[i] = tokenize(ds_train[i])\n",
    "for i in range(len(ds_test)):\n",
    "  ds_test[i] = tokenize(ds_test[i])\n",
    "for i in range(len(ds_val)):\n",
    "  ds_val[i] = tokenize(ds_val[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "031516d5089d8191e78e906aaec9fc12f69b6ded71cabf4c1fff4df0e2792dca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
